{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from absl import flags\n",
    "import numpy as np\n",
    "import six\n",
    "import tensorflow as tf\n",
    "import tensorflow_ranking as tfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags.DEFINE_string(\"train_path\", \"./data/train.txt\", \"Input file path used for training.\")\n",
    "flags.DEFINE_string(\"vali_path\", \"./data/vali.txt\", \"Input file path used for validation.\")\n",
    "flags.DEFINE_string(\"test_path\", \"./data/test.txt\", \"Input file path used for testing.\")\n",
    "flags.DEFINE_string(\"output_dir\", \"./output\", \"Output directory for models.\")\n",
    "flags.DEFINE_integer(\"train_batch_size\", 32, \"The batch size for training.\")\n",
    "flags.DEFINE_integer(\"num_train_steps\", 100, \"Number of steps for training.\")\n",
    "flags.DEFINE_float(\"learning_rate\", 0.01, \"Learning rate for optimizer.\")\n",
    "flags.DEFINE_float(\"dropout_rate\", 0.5, \"The dropout rate before output layer.\")\n",
    "flags.DEFINE_list(\"hidden_layer_dims\", [\"16\", \"8\", \"4\"],\"Sizes for hidden layers.\")\n",
    "flags.DEFINE_integer(\"num_features\", 136, \"Number of features per document.\")\n",
    "flags.DEFINE_integer(\"list_size\", 100, \"List size used for training.\")\n",
    "flags.DEFINE_integer(\"group_size\", 1, \"Group size used in score function.\")\n",
    "flags.DEFINE_string(\"loss\", \"pairwise_logistic_loss\",\"The RankingLossKey for the primary loss function.\")\n",
    "flags.DEFINE_string(\"secondary_loss\", None, \"The RankingLossKey for the secondary loss for \"\"multi-objective learning.\")\n",
    "flags.DEFINE_float(\"secondary_loss_weight\", 0.5, \"The weight for the secondary loss in \"\"multi-objective learning.\")\n",
    "FLAGS = flags.FLAGS\n",
    "_PRIMARY_HEAD = \"primary_head\"\n",
    "_SECONDARY_HEAD = \"secondary_head\"\n",
    "\n",
    "def _use_multi_head():\n",
    "  \"\"\"Returns True if using multi-head.\"\"\"\n",
    "  return FLAGS.secondary_loss is not None\n",
    "\n",
    "class IteratorInitializerHook(tf.estimator.SessionRunHook):\n",
    "  \"\"\"Hook to initialize data iterator after session is created.\"\"\"\n",
    "  def __init__(self):\n",
    "    super(IteratorInitializerHook, self).__init__()\n",
    "    self.iterator_initializer_fn = None\n",
    "\n",
    "  def after_create_session(self, session, coord):\n",
    "    \"\"\"Initialize the iterator after the session has been created.\"\"\"\n",
    "    del coord\n",
    "    self.iterator_initializer_fn(session)\n",
    "    \n",
    "def example_feature_columns():\n",
    "  \"\"\"Returns the example feature columns.\"\"\"\n",
    "  feature_names = [\"{}\".format(i + 1) for i in range(FLAGS.num_features)]\n",
    "  return {\n",
    "      name:\n",
    "      tf.feature_column.numeric_column(name, shape=(1,), default_value=0.0)\n",
    "      for name in feature_names\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_libsvm_data(path, list_size):\n",
    "  \"\"\"Returns features and labels in numpy.array.\"\"\"\n",
    "\n",
    "  def _parse_line(line):\n",
    "    \"\"\"Parses a single line in LibSVM format.\"\"\"\n",
    "    tokens = line.split(\"#\")[0].split()\n",
    "    assert len(tokens) >= 2, \"Ill-formatted line: {}\".format(line)\n",
    "    label = float(tokens[0])\n",
    "    qid = tokens[1]\n",
    "    kv_pairs = [kv.split(\":\") for kv in tokens[2:]]\n",
    "    features = {k: float(v) for (k, v) in kv_pairs}\n",
    "    return qid, features, label\n",
    "\n",
    "  # The 0-based index assigned to a query.\n",
    "  qid_to_index = {}\n",
    "  # The number of docs seen so far for a query.\n",
    "  qid_to_ndoc = {}\n",
    "  # Each feature is mapped an array with [num_queries, list_size, 1]. Label has\n",
    "  # a shape of [num_queries, list_size]. We use list for each of them due to the\n",
    "  # unknown number of queries.\n",
    "  feature_map = {k: [] for k in example_feature_columns()}\n",
    "  label_list = []\n",
    "  total_docs = 0\n",
    "  discarded_docs = 0\n",
    "  with open(path, \"rt\") as f:\n",
    "    for line in f:\n",
    "      qid, features, label = _parse_line(line)\n",
    "      if qid not in qid_to_index:\n",
    "        # Create index and allocate space for a new query.\n",
    "        qid_to_index[qid] = len(qid_to_index)\n",
    "        qid_to_ndoc[qid] = 0\n",
    "        for k in feature_map:\n",
    "          feature_map[k].append(np.zeros([list_size, 1], dtype=np.float32))\n",
    "        label_list.append(np.ones([list_size], dtype=np.float32) * -1.)\n",
    "      total_docs += 1\n",
    "      batch_idx = qid_to_index[qid]\n",
    "      doc_idx = qid_to_ndoc[qid]\n",
    "      qid_to_ndoc[qid] += 1\n",
    "      # Keep the first 'list_size' docs only.\n",
    "      if doc_idx >= list_size:\n",
    "        discarded_docs += 1\n",
    "        continue\n",
    "      for k, v in six.iteritems(features):\n",
    "        assert k in feature_map, \"Key {} not found in features.\".format(k)\n",
    "        feature_map[k][batch_idx][doc_idx, 0] = v\n",
    "      label_list[batch_idx][doc_idx] = label\n",
    "\n",
    "  # Convert everything to np.array.\n",
    "  for k in feature_map:\n",
    "    feature_map[k] = np.array(feature_map[k])\n",
    "  return feature_map, np.array(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_inputs(features, labels, batch_size):\n",
    "  \"\"\"Set up training input in batches.\"\"\"\n",
    "  iterator_initializer_hook = IteratorInitializerHook()\n",
    "\n",
    "  def _train_input_fn():\n",
    "    \"\"\"Defines training input fn.\"\"\"\n",
    "    features_placeholder = {\n",
    "        k: tf.compat.v1.placeholder(v.dtype, v.shape)\n",
    "        for k, v in six.iteritems(features)\n",
    "    }\n",
    "    if _use_multi_head():\n",
    "      placeholder = tf.compat.v1.placeholder(labels.dtype, labels.shape)\n",
    "      labels_placeholder = {\n",
    "          _PRIMARY_HEAD: placeholder,\n",
    "          _SECONDARY_HEAD: placeholder,\n",
    "      }\n",
    "    else:\n",
    "      labels_placeholder = tf.compat.v1.placeholder(labels.dtype, labels.shape)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (features_placeholder, labels_placeholder))\n",
    "    dataset = dataset.shuffle(1000).repeat().batch(batch_size)\n",
    "    iterator = tf.compat.v1.data.make_initializable_iterator(dataset)\n",
    "    if _use_multi_head():\n",
    "      feed_dict = {\n",
    "          labels_placeholder[head_name]: labels\n",
    "          for head_name in labels_placeholder\n",
    "      }\n",
    "    else:\n",
    "      feed_dict = {labels_placeholder: labels}\n",
    "    feed_dict.update(\n",
    "        {features_placeholder[k]: features[k] for k in features_placeholder})\n",
    "    iterator_initializer_hook.iterator_initializer_fn = (\n",
    "        lambda sess: sess.run(iterator.initializer, feed_dict=feed_dict))\n",
    "    return iterator.get_next()\n",
    "\n",
    "  return _train_input_fn, iterator_initializer_hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eval_inputs(features, labels):\n",
    "  \"\"\"Set up eval inputs in a single batch.\"\"\"\n",
    "  iterator_initializer_hook = IteratorInitializerHook()\n",
    "\n",
    "  def _eval_input_fn():\n",
    "    \"\"\"Defines eval input fn.\"\"\"\n",
    "    features_placeholder = {\n",
    "        k: tf.compat.v1.placeholder(v.dtype, v.shape)\n",
    "        for k, v in six.iteritems(features)\n",
    "    }\n",
    "    if _use_multi_head():\n",
    "      placeholder = tf.compat.v1.placeholder(labels.dtype, labels.shape)\n",
    "      labels_placeholder = {\n",
    "          _PRIMARY_HEAD: placeholder,\n",
    "          _SECONDARY_HEAD: placeholder,\n",
    "      }\n",
    "    else:\n",
    "      labels_placeholder = tf.compat.v1.placeholder(labels.dtype, labels.shape)\n",
    "    dataset = tf.data.Dataset.from_tensors(\n",
    "        (features_placeholder, labels_placeholder))\n",
    "    iterator = tf.compat.v1.data.make_initializable_iterator(dataset)\n",
    "    if _use_multi_head():\n",
    "      feed_dict = {\n",
    "          labels_placeholder[head_name]: labels\n",
    "          for head_name in labels_placeholder\n",
    "      }\n",
    "    else:\n",
    "      feed_dict = {labels_placeholder: labels}\n",
    "    feed_dict.update(\n",
    "        {features_placeholder[k]: features[k] for k in features_placeholder})\n",
    "    iterator_initializer_hook.iterator_initializer_fn = (\n",
    "        lambda sess: sess.run(iterator.initializer, feed_dict=feed_dict))\n",
    "    return iterator.get_next()\n",
    "\n",
    "  return _eval_input_fn, iterator_initializer_hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_serving_input_fn():\n",
    "  \"\"\"Returns serving input fn to receive tf.Example.\"\"\"\n",
    "  feature_spec = tf.feature_column.make_parse_example_spec(\n",
    "      example_feature_columns().values())\n",
    "  return tf.estimator.export.build_parsing_serving_input_receiver_fn(\n",
    "      feature_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_transform_fn():\n",
    "  \"\"\"Returns a transform_fn that converts features to dense Tensors.\"\"\"\n",
    "\n",
    "  def _transform_fn(features, mode):\n",
    "    \"\"\"Defines transform_fn.\"\"\"\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "      # We expect tf.Example as input during serving. In this case, group_size\n",
    "      # must be set to 1.\n",
    "      if FLAGS.group_size != 1:\n",
    "        raise ValueError(\n",
    "            \"group_size should be 1 to be able to export model, but get %s\" %\n",
    "            FLAGS.group_size)\n",
    "      context_features, example_features = (\n",
    "          tfr.feature.encode_pointwise_features(\n",
    "              features=features,\n",
    "              context_feature_columns=None,\n",
    "              example_feature_columns=example_feature_columns(),\n",
    "              mode=mode,\n",
    "              scope=\"transform_layer\"))\n",
    "    else:\n",
    "      context_features, example_features = tfr.feature.encode_listwise_features(\n",
    "          features=features,\n",
    "          context_feature_columns=None,\n",
    "          example_feature_columns=example_feature_columns(),\n",
    "          mode=mode,\n",
    "          scope=\"transform_layer\")\n",
    "\n",
    "    return context_features, example_features\n",
    "\n",
    "  return _transform_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_score_fn():\n",
    "  \"\"\"Returns a groupwise score fn to build `EstimatorSpec`.\"\"\"\n",
    "\n",
    "  def _score_fn(unused_context_features, group_features, mode, unused_params,\n",
    "                unused_config):\n",
    "    \"\"\"Defines the network to score a group of documents.\"\"\"\n",
    "    with tf.compat.v1.name_scope(\"input_layer\"):\n",
    "      group_input = [\n",
    "          tf.compat.v1.layers.flatten(group_features[name])\n",
    "          for name in sorted(example_feature_columns())\n",
    "      ]\n",
    "      input_layer = tf.concat(group_input, 1)\n",
    "      tf.compat.v1.summary.scalar(\"input_sparsity\",\n",
    "                                  tf.nn.zero_fraction(input_layer))\n",
    "      tf.compat.v1.summary.scalar(\"input_max\",\n",
    "                                  tf.reduce_max(input_tensor=input_layer))\n",
    "      tf.compat.v1.summary.scalar(\"input_min\",\n",
    "                                  tf.reduce_min(input_tensor=input_layer))\n",
    "\n",
    "    is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
    "    cur_layer = tf.compat.v1.layers.batch_normalization(\n",
    "        input_layer, training=is_training)\n",
    "    for i, layer_width in enumerate(int(d) for d in FLAGS.hidden_layer_dims):\n",
    "      cur_layer = tf.compat.v1.layers.dense(cur_layer, units=layer_width)\n",
    "      cur_layer = tf.compat.v1.layers.batch_normalization(\n",
    "          cur_layer, training=is_training)\n",
    "      cur_layer = tf.nn.relu(cur_layer)\n",
    "      tf.compat.v1.summary.scalar(\"fully_connected_{}_sparsity\".format(i),\n",
    "                                  tf.nn.zero_fraction(cur_layer))\n",
    "    cur_layer = tf.compat.v1.layers.dropout(\n",
    "        cur_layer, rate=FLAGS.dropout_rate, training=is_training)\n",
    "    logits = tf.compat.v1.layers.dense(cur_layer, units=FLAGS.group_size)\n",
    "    if _use_multi_head():\n",
    "      # Duplicate the logits for both heads.\n",
    "      return {_PRIMARY_HEAD: logits, _SECONDARY_HEAD: logits}\n",
    "    else:\n",
    "      return logits\n",
    "\n",
    "  return _score_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eval_metric_fns():\n",
    "  \"\"\"Returns a dict from name to metric functions.\"\"\"\n",
    "  metric_fns = {}\n",
    "  metric_fns.update({\n",
    "      \"metric/%s\" % name: tfr.metrics.make_ranking_metric_fn(name) for name in [\n",
    "          tfr.metrics.RankingMetricKey.ARP,\n",
    "          tfr.metrics.RankingMetricKey.ORDERED_PAIR_ACCURACY,\n",
    "      ]\n",
    "  })\n",
    "  metric_fns.update({\n",
    "      \"metric/ndcg@%d\" % topn: tfr.metrics.make_ranking_metric_fn(\n",
    "          tfr.metrics.RankingMetricKey.NDCG, topn=topn)\n",
    "      for topn in [1, 3, 5, 10]\n",
    "  })\n",
    "  return metric_fns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval():\n",
    "  \"\"\"Train and Evaluate.\"\"\"\n",
    "\n",
    "  features, labels = load_libsvm_data(FLAGS.train_path, FLAGS.list_size)\n",
    "  train_input_fn, train_hook = get_train_inputs(features, labels,\n",
    "                                                FLAGS.train_batch_size)\n",
    "\n",
    "  features_vali, labels_vali = load_libsvm_data(FLAGS.vali_path,\n",
    "                                                FLAGS.list_size)\n",
    "  vali_input_fn, vali_hook = get_eval_inputs(features_vali, labels_vali)\n",
    "\n",
    "  features_test, labels_test = load_libsvm_data(FLAGS.test_path,\n",
    "                                                FLAGS.list_size)\n",
    "  test_input_fn, test_hook = get_eval_inputs(features_test, labels_test)\n",
    "\n",
    "  optimizer = tf.compat.v1.train.AdagradOptimizer(\n",
    "      learning_rate=FLAGS.learning_rate)\n",
    "\n",
    "  def _train_op_fn(loss):\n",
    "    \"\"\"Defines train op used in ranking head.\"\"\"\n",
    "    update_ops = tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.UPDATE_OPS)\n",
    "    minimize_op = optimizer.minimize(\n",
    "        loss=loss, global_step=tf.compat.v1.train.get_global_step())\n",
    "    train_op = tf.group([minimize_op, update_ops])\n",
    "    return train_op\n",
    "\n",
    "  if _use_multi_head():\n",
    "    primary_head = tfr.head.create_ranking_head(\n",
    "        loss_fn=tfr.losses.make_loss_fn(FLAGS.loss),\n",
    "        eval_metric_fns=get_eval_metric_fns(),\n",
    "        train_op_fn=_train_op_fn,\n",
    "        name=_PRIMARY_HEAD)\n",
    "    secondary_head = tfr.head.create_ranking_head(\n",
    "        loss_fn=tfr.losses.make_loss_fn(FLAGS.secondary_loss),\n",
    "        eval_metric_fns=get_eval_metric_fns(),\n",
    "        train_op_fn=_train_op_fn,\n",
    "        name=_SECONDARY_HEAD)\n",
    "    ranking_head = tfr.head.create_multi_ranking_head(\n",
    "        [primary_head, secondary_head], [1.0, FLAGS.secondary_loss_weight])\n",
    "  else:\n",
    "    ranking_head = tfr.head.create_ranking_head(\n",
    "        loss_fn=tfr.losses.make_loss_fn(FLAGS.loss),\n",
    "        eval_metric_fns=get_eval_metric_fns(),\n",
    "        train_op_fn=_train_op_fn)\n",
    "\n",
    "  estimator = tf.estimator.Estimator(\n",
    "      model_fn=tfr.model.make_groupwise_ranking_fn(\n",
    "          group_score_fn=make_score_fn(),\n",
    "          group_size=FLAGS.group_size,\n",
    "          transform_fn=make_transform_fn(),\n",
    "          ranking_head=ranking_head),\n",
    "      config=tf.estimator.RunConfig(\n",
    "          FLAGS.output_dir, save_checkpoints_steps=1000))\n",
    "\n",
    "  train_spec = tf.estimator.TrainSpec(\n",
    "      input_fn=train_input_fn,\n",
    "      hooks=[train_hook],\n",
    "      max_steps=FLAGS.num_train_steps)\n",
    "    \n",
    "  # Export model to accept tf.Example when group_size = 1.\n",
    "  if FLAGS.group_size == 1:\n",
    "    vali_spec = tf.estimator.EvalSpec(input_fn=vali_input_fn,hooks=[vali_hook],steps=1,\n",
    "                                        exporters=tf.estimator.LatestExporter(\"latest_exporter\",\n",
    "                                        serving_input_receiver_fn=make_serving_input_fn()),\n",
    "                                        start_delay_secs=0,\n",
    "                                        throttle_secs=30)\n",
    "  else:\n",
    "    vali_spec = tf.estimator.EvalSpec(input_fn=vali_input_fn,hooks=[vali_hook],steps=1,start_delay_secs=0,throttle_secs=30)\n",
    "\n",
    "  # Train and validate\n",
    "  tf.estimator.train_and_evaluate(estimator, train_spec, vali_spec)\n",
    "\n",
    "  # Evaluate on the test data.\n",
    "  estimator.evaluate(input_fn=test_input_fn, hooks=[test_hook])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Building groupwise ranking model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/absl/flags/_validators.py:356: UserWarning: Flag --train_path has a non-None default value; therefore, mark_flag_as_required will pass even if flag is not specified in the command line!\n",
      "  'command line!' % flag_name)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/absl/flags/_validators.py:356: UserWarning: Flag --vali_path has a non-None default value; therefore, mark_flag_as_required will pass even if flag is not specified in the command line!\n",
      "  'command line!' % flag_name)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/absl/flags/_validators.py:356: UserWarning: Flag --test_path has a non-None default value; therefore, mark_flag_as_required will pass even if flag is not specified in the command line!\n",
      "  'command line!' % flag_name)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/absl/flags/_validators.py:356: UserWarning: Flag --output_dir has a non-None default value; therefore, mark_flag_as_required will pass even if flag is not specified in the command line!\n",
      "  'command line!' % flag_name)\n",
      "I0103 09:27:10.114405 4654501312 model.py:469] Building groupwise ranking model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': './output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0103 09:27:10.116680 4654501312 estimator.py:191] Using config: {'_model_dir': './output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Estimator's model_fn (<function _make_model_fn.<locals>._model_fn at 0x641e42b00>) includes params argument, but params are not passed to Estimator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0103 09:27:10.118277 4654501312 model_fn.py:629] Estimator's model_fn (<function _make_model_fn.<locals>._model_fn at 0x641e42b00>) includes params argument, but params are not passed to Estimator.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0103 09:27:10.120985 4654501312 estimator_training.py:186] Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0103 09:27:10.122282 4654501312 training.py:645] Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 1000 or save_checkpoints_secs None.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0103 09:27:10.123524 4654501312 training.py:733] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 1000 or save_checkpoints_secs None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Applications/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0103 09:27:10.130714 4654501312 deprecation.py:339] From /Applications/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0103 09:27:10.249648 4654501312 estimator.py:1162] Calling model_fn.\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/legacy_tf_layers/core.py:329: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
      "  warnings.warn('`tf.layers.flatten` is deprecated and '\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1719: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/legacy_tf_layers/normalization.py:308: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
      "  '`tf.layers.batch_normalization` is deprecated and '\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/legacy_tf_layers/core.py:171: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  warnings.warn('`tf.layers.dense` is deprecated and '\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/legacy_tf_layers/core.py:268: UserWarning: `tf.layers.dropout` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dropout` instead.\n",
      "  warnings.warn('`tf.layers.dropout` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Applications/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/adagrad.py:77: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0103 09:27:12.989562 4654501312 deprecation.py:537] From /Applications/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/adagrad.py:77: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0103 09:27:13.067068 4654501312 estimator.py:1164] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0103 09:27:13.069098 4654501312 basic_session_run_hooks.py:546] Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0103 09:27:13.884187 4654501312 monitored_session.py:246] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0103 09:27:14.143487 4654501312 session_manager.py:505] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0103 09:27:14.182004 4654501312 session_manager.py:508] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0103 09:27:16.487659 4654501312 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 0...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into ./output/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0103 09:27:16.491793 4654501312 basic_session_run_hooks.py:618] Saving checkpoints for 0 into ./output/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0103 09:27:16.924762 4654501312 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 0...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.4102677, step = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0103 09:27:18.264658 4654501312 basic_session_run_hooks.py:262] loss = 1.4102677, step = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 100...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0103 09:27:20.802803 4654501312 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 100...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 100 into ./output/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0103 09:27:20.803761 4654501312 basic_session_run_hooks.py:618] Saving checkpoints for 100 into ./output/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 100...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0103 09:27:21.197050 4654501312 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 100...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0103 09:27:21.279611 4654501312 estimator.py:1162] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0103 09:27:24.190006 4654501312 estimator.py:1164] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2021-01-03T09:27:24Z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0103 09:27:24.209874 4654501312 evaluation.py:255] Starting evaluation at 2021-01-03T09:27:24Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0103 09:27:24.389809 4654501312 monitored_session.py:246] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./output/model.ckpt-100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0103 09:27:24.391752 4654501312 saver.py:1292] Restoring parameters from ./output/model.ckpt-100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0103 09:27:24.614490 4654501312 session_manager.py:505] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0103 09:27:24.665274 4654501312 session_manager.py:508] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [1/1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0103 09:27:25.296639 4654501312 evaluation.py:167] Evaluation [1/1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Inference Time : 1.16788s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0103 09:27:25.378810 4654501312 evaluation.py:273] Inference Time : 1.16788s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2021-01-03-09:27:25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0103 09:27:25.380303 4654501312 evaluation.py:276] Finished evaluation at 2021-01-03-09:27:25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 100: global_step = 100, labels_mean = 0.7777778, logits_mean = -0.11944391, loss = 0.6866768, metric/arp = 2.892857, metric/ndcg@1 = 0.6296297, metric/ndcg@10 = 0.8509783, metric/ndcg@3 = 0.8351909, metric/ndcg@5 = 0.8210182, metric/ordered_pair_accuracy = 0.59322035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0103 09:27:25.381292 4654501312 estimator.py:2066] Saving dict for global step 100: global_step = 100, labels_mean = 0.7777778, logits_mean = -0.11944391, loss = 0.6866768, metric/arp = 2.892857, metric/ndcg@1 = 0.6296297, metric/ndcg@10 = 0.8509783, metric/ndcg@3 = 0.8351909, metric/ndcg@5 = 0.8210182, metric/ordered_pair_accuracy = 0.59322035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 100: ./output/model.ckpt-100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0103 09:27:26.092410 4654501312 estimator.py:2127] Saving 'checkpoint_path' summary for global step 100: ./output/model.ckpt-100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0103 09:27:26.224318 4654501312 estimator.py:1162] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0103 09:27:27.906394 4654501312 estimator.py:1164] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Applications/anaconda3/lib/python3.7/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:95: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0103 09:27:27.907416 4654501312 deprecation.py:339] From /Applications/anaconda3/lib/python3.7/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:95: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0103 09:27:27.908360 4654501312 export_utils.py:170] Signatures INCLUDED in export for Classify: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: ['serving_default', 'regression']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0103 09:27:27.909478 4654501312 export_utils.py:170] Signatures INCLUDED in export for Regress: ['serving_default', 'regression']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0103 09:27:27.910326 4654501312 export_utils.py:170] Signatures INCLUDED in export for Predict: ['predict']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0103 09:27:27.911052 4654501312 export_utils.py:170] Signatures INCLUDED in export for Train: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0103 09:27:27.911961 4654501312 export_utils.py:170] Signatures INCLUDED in export for Eval: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./output/model.ckpt-100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0103 09:27:27.947347 4654501312 saver.py:1292] Restoring parameters from ./output/model.ckpt-100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0103 09:27:28.044926 4654501312 builder_impl.py:666] Assets added to graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0103 09:27:28.046304 4654501312 builder_impl.py:461] No assets to write.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: ./output/export/latest_exporter/temp-1609684046/saved_model.pb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0103 09:27:28.408173 4654501312 builder_impl.py:426] SavedModel written to: ./output/export/latest_exporter/temp-1609684046/saved_model.pb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 0.5013943.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0103 09:27:28.481143 4654501312 estimator.py:350] Loss for final step: 0.5013943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0103 09:27:28.571753 4654501312 estimator.py:1162] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0103 09:27:31.782512 4654501312 estimator.py:1164] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2021-01-03T09:27:31Z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0103 09:27:31.800949 4654501312 evaluation.py:255] Starting evaluation at 2021-01-03T09:27:31Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0103 09:27:31.877606 4654501312 monitored_session.py:246] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./output/model.ckpt-100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0103 09:27:31.879103 4654501312 saver.py:1292] Restoring parameters from ./output/model.ckpt-100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0103 09:27:32.106362 4654501312 session_manager.py:505] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0103 09:27:32.156197 4654501312 session_manager.py:508] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Inference Time : 1.11137s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0103 09:27:32.913262 4654501312 evaluation.py:273] Inference Time : 1.11137s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2021-01-03-09:27:32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0103 09:27:32.914810 4654501312 evaluation.py:276] Finished evaluation at 2021-01-03-09:27:32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 100: global_step = 100, labels_mean = 0.7777778, logits_mean = -0.11944391, loss = 0.6866768, metric/arp = 2.892857, metric/ndcg@1 = 0.5555556, metric/ndcg@10 = 0.8509783, metric/ndcg@3 = 0.8351909, metric/ndcg@5 = 0.83759224, metric/ordered_pair_accuracy = 0.59322035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0103 09:27:32.915724 4654501312 estimator.py:2066] Saving dict for global step 100: global_step = 100, labels_mean = 0.7777778, logits_mean = -0.11944391, loss = 0.6866768, metric/arp = 2.892857, metric/ndcg@1 = 0.5555556, metric/ndcg@10 = 0.8509783, metric/ndcg@3 = 0.8351909, metric/ndcg@5 = 0.83759224, metric/ordered_pair_accuracy = 0.59322035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 100: ./output/model.ckpt-100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0103 09:27:32.917095 4654501312 estimator.py:2127] Saving 'checkpoint_path' summary for global step 100: ./output/model.ckpt-100\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3334: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "def main(_):\n",
    "  tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\n",
    "  train_and_eval()\n",
    "if __name__ == \"__main__\":\n",
    "  flags.mark_flag_as_required(\"train_path\")\n",
    "  flags.mark_flag_as_required(\"vali_path\")\n",
    "  flags.mark_flag_as_required(\"test_path\")\n",
    "  flags.mark_flag_as_required(\"output_dir\")\n",
    "    \n",
    "  tf.compat.v1.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Could not find `tensorboard`. Please ensure that your PATH\n",
       "contains an executable `tensorboard` program, or explicitly specify\n",
       "the path to a TensorBoard binary by setting the `TENSORBOARD_BINARY`\n",
       "environment variable."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=\"./output\" --port 12345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
